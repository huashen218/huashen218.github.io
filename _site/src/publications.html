<!DOCTYPE html>
<html lang="en">

  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>Hua Shen</title>
    <meta name="description" content="description.">
    
    <link rel="stylesheet" href="/assets/css/main.css">
    <link rel="canonical" href="http://localhost:4000/">
    <link rel="alternate" type="application/rss+xml" title="Hua Shen" href="/feed.xml">
    <meta name="theme-color" content="#ffffff">
    <!-- <link rel="icon" href="/assets/images/favicon-32x32.png" sizes="16x16" type="image/png"> -->
    <link rel="icon" href="/assets/images/lab_icon.png" sizes="16x16" type="image/png">
</head>

  <body>

    

<header class="site-header" role="banner">
    <div class="wrapper">
        <div class="site-header-float">
        <a class="site-title" href="/index.html" >Hua Shen</a>
        <nav class="site-nav">
            <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
                <path fill="#424242" d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.031C17.335,0,18,0.665,18,1.484L18,1.484z"/>
                <path fill="#424242" d="M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0c0-0.82,0.665-1.484,1.484-1.484 h15.031C17.335,6.031,18,6.696,18,7.516L18,7.516z"/>
                <path fill="#424242" d="M18,13.516C18,14.335,17.335,15,16.516,15H1.484C0.665,15,0,14.335,0,13.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.031C17.335,12.031,18,12.696,18,13.516L18,13.516z"/>
            </svg>
            </span>

            <div class="trigger">
            <span class="nav-list-title">Menu:</span>
                <nav>
    <ul class="nav-list ">
        <li><a class="page-link" href="/index.html" style="font-size: 20px">About</a></li>
        <li><a class="page-link" href="/src/publications.html" style="font-size: 20px">Publications</a></li>
        <li><a class="page-link" href="/src/teaching.html" style="font-size: 20px">Teaching</a></li>
        <li><a class="page-link" href="/src/course_bialign.html" style="font-size: 20px">BiAlign Course</a></li>
        <li><a class="page-link" href="/src/misc.html" style="font-size: 20px">Talks</a></li>
        <li><a class="page-link" href="/src/lab.html" style="font-size: 20px">BiAlign Lab</a></li>
    </ul>
</nav>

            </div>
        </nav>
        </div>
    </div>
</header>

    <main class="page-content" aria-label="Content">
      <meta name="viewport" content="width=device-width, initial-scale=1.0">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.1.2/css/all.min.css"
integrity="sha512-1sCRPdkRXhBV2PBLUdRb4tMg1w2YPf37qatUFeS7zlBy7jJI8Lf4VHwWfZZfpXtYSLy85pkm9GaYVYMfw5BC1A=="
crossorigin="anonymous" referrerpolicy="no-referrer" />



<div class="pagewrapper">
  <h1 class="post-title" itemprop="name headline">Publications</h1>
  <br>
  <div>
  <div>

    <div class="section-title"> <span>Recent Preprints</span>  |  <a class="post-link" href="https://scholar.google.com/citations?user=zFjlv1sAAAAJ&hl=en" target="_blank"><i class="fa-brands fa-google"></i> [Google Scholar]</a></div>

    <span>
    <ol reversed  start="32">

      <li class="publist">
        <span><strong>The Siren Song of LLMs: How Users Perceive and Respond to Dark Patterns in Large Language Models</strong></span>
        <br>
        <span class="pubindent" >Yike Shi, Qing Xiao, Qing (Diane) Hu, Hong Shen, <strong style= "text-decoration: underline">Hua Shen</strong></span>
        <br>
        <span class="pubindent">
          <a class="post-link" href="https://www.arxiv.org/pdf/2509.10830" target="_blank"><i class='fas fa-atlas'></i> [Arxiv: 2509.10830]</a>
        </span>
      </li>

      
      <li class="publist">
        <span><strong>Beyond One-Way Influence: Bidirectional Opinion Dynamics in Multi-Turn Human-LLM Interactions</strong></span>
        <br>
        <span class="pubindent" >Yuyang Jiang, Longjie Guo, Yuchen Wu, Aylin Caliskan, Tanushree Mitra, <strong style= "text-decoration: underline">Hua Shen</strong></span>
        <br>
        <span class="pubindent">
          <a class="post-link" href="../assets/files/CHI2026_Biopinion.pdf" target="_blank"><i class='fas fa-atlas'></i> [Paper]</a>
        </span>
      </li>


      <li class="publist">
        <span><strong>Towards Bidirectional Human-AI Alignment: A Systematic Review for Clarifications, Framework, and Future Directions</strong></span>
        <br>
        <span class="pubindent" ><strong style= "text-decoration: underline">Hua Shen</strong>, Tiffany Knearem, Reshmi Ghosh, Kenan Alkiek, Kundan Krishna, Yachuan Liu, Ziqiao Ma, Savvas Petridis, Yi-Hao Peng, Li Qiwei, Sushrita Rakshit, Chenglei Si, Yutong Xie, Jeffrey P. Bigham, Frank Bentley, Joyce Chai, Zachary Lipton, Qiaozhu Mei, Rada Mihalcea, Michael Terry, Diyi Yang, Meredith Ringel Morris, Paul Resnick, David Jurgens </span>
        <br>
        <span class="pubindent">
          <a class="post-link" href="https://arxiv.org/abs/2406.09264" target="_blank"><i class='fas fa-atlas'></i> [ArXiv:2409.09586]</a>
        </span>
        |  <span><a class="post-link" href="https://github.com/huashen218/bidirectional-alignment-reading-list/" target=”_blank”><i class="fa-solid fa-book-open"></i> [Reading List]</a></span>
        |  <span class="pubindent text-primary" style="color:#D84C19; font-weight:bold"><i class="fa-solid fa-briefcase"></i> <a class="post-link" href="https://bialign-workshop.github.io/#/" target=”_blank”> [ICLR & CHI BiAlign Workshop]</a></span>
      </li>



    </ol>
    </span>


    <div class="section-title"> <span>Selected Papers</span> </div>
    

    <span>


    <ol reversed start="29">

      <li class="publist">
        <span><strong>Deep Value Benchmark: Measuring Whether Models Generalize Deep Values or Shallow Preferences</strong></span>
        <br>
        <span class="pubindent" >Joshua Ashkinaze, <strong style= "text-decoration: underline">Hua Shen</strong>, Sai Avula, Eric Gilbert, Ceren Budak </span>
        <br>
        <span class="pubindent"><a class="post-link" href="" target="_blank">NeurIPS 2025</a><span class="pubindent text-primary" style="color:#D84C19; font-weight:bold"><i class="fa-solid fa-star"></i>Spotlight</span>
        |  <a class="post-link" href="" target="_blank"><i class='fas fa-atlas'></i>   [Paper]</a>
        </span>
      </li>

      <li class="publist">
        <span><strong>ValueCompass: A Framework for Measuring Contextual Value Alignment Between Human and LLMs</strong></span>
        <br>
        <span class="pubindent" ><strong style= "text-decoration: underline">Hua Shen</strong>, Tiffany Knearem, Reshmi Ghosh, Yu-Ju Yang, Nicholas Clark, Tanu Mitra*, Yun Huang* </span>
        <br>
        <span class="pubindent"><a class="post-link" href="https://winlp-workshop.github.io/" target="_blank">EMNLP 2025 WiNLP Workshop</a> |
          <a class="post-link" href="https://arxiv.org/pdf/2409.09586" target="_blank"><i class='fas fa-atlas'></i> [Paper]</a>
        </span>
      </li>

      <li class="publist">
        <span><strong>Mind the Value-Action Gap: Do LLMs Act in Alignment with Their Values?</strong></span>
        <br>
        <span class="pubindent" ><strong style= "text-decoration: underline">Hua Shen</strong>, Nicholas Clark, Tanu Mitra </span>
        <br>
        <span class="pubindent"><a class="post-link" href="https://arxiv.org/pdf/2501.15463" target="_blank">EMNLP 2025 Main</a> |
        <a class="post-link" href="https://arxiv.org/pdf/2501.15463" target="_blank">
          <i class='fas fa-atlas'></i> [Paper]</a>
        </span>
      </li>


      <li class="publist">
        <span><strong>ICLR 2025 Workshop on Bidirectional Human-AI Alignment</strong></span>
        <br>
        <span class="pubindent" ><strong style= "text-decoration: underline">Hua Shen</strong>,Tiffany Knearem, Reshmi Ghosh, 
          Michael Liu, Andrés Monroy-Hernández, Tongshuang Wu, Diyi Yang, Yun Huang, Tanushree Mitra, Yang Li, Marti A. Hearst</span>
        <br>
        <span class="pubindent"><a class="post-link" href="https://dl.acm.org/doi/abs/10.1145/3706599.3716291" target="_blank">CHI 2025</a> |
        <a class="post-link" href="https://dl.acm.org/doi/abs/10.1145/3706599.3716291" target="_blank">
          <i class='fas fa-atlas'></i> [BiAlign SIG Proposal]</a>
        </span>
      </li>


      <li class="publist">
        <span><strong>Bidirectional Human-AI Alignment: Emerging Challenges and Opportunities</strong></span>
        <br>
        <span class="pubindent" ><strong style= "text-decoration: underline">Hua Shen</strong>, Ziqiao Ma, Reshmi Ghosh, Tiffany Knearem,
          Michael Liu, Tongshuang Wu, Andres Monroy-Hern ´ andez, Diyi Yang, Antoine Bosselut ´
          Furong Huang, Tanu Mitra, Joyce Chai, Marti A. Hearst, Dawn Song, Yang Li</span>
        <br>
        <span class="pubindent"><a class="post-link" href="https://openreview.net/pdf?id=HcTiacDN8N" target="_blank">ICLR 2025</a> |
        <a class="post-link" href="https://openreview.net/pdf?id=HcTiacDN8N" target="_blank">
          <i class='fas fa-atlas'></i> [BiAlign Workshop Proposal]</a>
        </span>
      </li>

      <li class="publist">
        <span><strong>MultiTurnCleanup: A Benchmark for Multi-Turn Spoken Conversational Transcript Cleanup</strong></span>
        <br>
        <span class="pubindent" ><strong style= "text-decoration: underline">Hua Shen</strong>, Vicky Zayats, Johann C. Rocholl, Daniel D. Walker, Dirk Padfield</span>
        <br>
        <span class="pubindent"><a class="post-link" href="https://aclanthology.org/2023.emnlp-main.613.pdf" target="_blank">EMNLP 2023 Main (Oral)</a>  | 
        <a class="post-link" href="https://aclanthology.org/2023.emnlp-main.613.pdf" target="_blank">
          <i class='fas fa-atlas'></i> [Paper]</a>
          | <a class="post-link" href="https://github.com/huashen218/MultiTurnCleanup.git" target="_blank"><i class="fa-brands fa-github"></i> [Dataset]</a>
        </span>
        <span class="pubindent text-primary" style="color:#D84C19; font-weight:bold"><i class="fa-solid fa-trophy"></i> Google Research Science Conference Scholarships</span>
      </li>


      <li class="publist">
        <span><strong>ConvXAI<img src="../assets/images/convxai_logo.png" style="width:30px;height:20px;">: Delivering Heterogeneous AI Explanations via Conversations to Support Human-AI Scientific Writing</strong></span>
        <br>
        <span class="pubindent" ><strong style= "text-decoration: underline">Hua Shen</strong>, Chieh-Yang Huang, Tongshuang Wu, Ting-Hao (Kenneth) Huang</span>
        <br>
        <span class="pubindent"><a class="post-link" href="https://arxiv.org/pdf/2305.09770" target="_blank">CSCW 2023 Demo</a>  
          | <a class="post-link" href="https://arxiv.org/pdf/2305.09770" target="_blank"><i class='fas fa-atlas'></i> [Long Paper]</a>
          | <a class="post-link" href="/assets/files/CSCW_2023_Demo.pdf" target="_blank"><i class='fas fa-atlas'></i> [Short Paper]</a>
          | <a class="post-link" href="https://github.com/huashen218/convxai" target="_blank"><i class="fa-brands fa-github"></i> [System]</a>
          | <a class="post-link" href="https://github.com/huashen218/convxai/blob/main/notebook_unified_XAI_API/convxai_unified_api.ipynb" target="_blank"><i class="fa-brands fa-github"></i> [XAI API]</a>
          | <a class="post-link" href="https://youtu.be/0RXRusy_3D8" target="_blank"><i class="fa-solid fa-video"></i> [Video]</a>  
        </span>
        <span class="pubindent text-primary" style="color:#D84C19; font-weight:bold"><i class="fa-solid fa-trophy"></i> Best Demo </span>
      </li>


      <li class="publist">
        <strong>Parachute: Evaluating Interactive Human-LM Co-writing Systems</strong>
        <br>
        <span class="pubindent" ><strong style= "text-decoration: underline">Hua Shen</strong>, Tongshuang Wu</span>
        <br>
        <span class="pubindent"><a class="post-link" href="https://arxiv.org/pdf/2303.06333.pdf" target="_blank">CHI 2023 In2Writing Workshop</a>  
          | <a class="post-link" href="https://arxiv.org/pdf/2303.06333.pdf" target="_blank"><i class='fas fa-atlas'></i> [Paper]</a>
          | <a class="post-link" href="https://twitter.com/huashen218/status/1650026788783812609?s=20" target="_blank"><i class="fa-brands fa-twitter"></i> [Tweet]</a>  
        </span>
      </li>


      <li class="publist">
        <span><strong>Does Human Collaboration Enhance the Accuracy of Identifying LLM-Generated Deepfake Texts?</strong></span>
        <br>
        <span class="pubindent" ><strong style= "text-decoration: underline">Hua Shen*</strong>, Adaku Uchendu*, Jooyoung Lee*,  Thai Le, Ting-Hao 'Kenneth' Huang, Dongwon Lee</span>
        <br>
        <span class="pubindent"><a class="post-link" href="https://arxiv.org/pdf/2304.01002" target="_blank">AAAI HCOMP 2023</a>  
          | <a class="post-link" href="https://arxiv.org/pdf/2304.01002" target="_blank"><i class='fas fa-atlas'></i> [Paper]</a>
          | <a class="post-link" href="https://github.com/huashen218/llm-deepfake-human-study" target="_blank"><i class="fa-brands fa-github"></i> [Github]</a>
        </span>
      </li>



      <li class="publist">
        <strong>Are Shortest Rationales the Best Explanations For Human Understanding?</strong>
        <br>
        <span class="pubindent" ><strong style= "text-decoration: underline">Hua Shen</strong>, Tongshuang Wu, Wenbo Guo, Ting-Hao (Kenneth) Huang</span>
        <br>
        <span class="pubindent"><a class="post-link" href="https://arxiv.org/pdf/2203.08788.pdf" target="_blank">ACL 2022</a>  
          | <a class="post-link" href="https://arxiv.org/pdf/2203.08788.pdf" target="_blank"><i class='fas fa-atlas'></i> [Paper]</a>
          | <a class="post-link" href="https://github.com/huashen218/LimitedInk.git" target="_blank"><i class="fa-brands fa-github"></i> [Github]</a>
          | <a class="post-link" href="/assets/files/submission-ACL22-poster.pdf" target="_blank"><i class="fa-solid fa-globe"></i> [Poster]</a>
          | <a class="post-link" href="/assets/files/submission-ACL22-presentation-slides.pdf" target="_blank"><i class="fa-solid fa-video"></i> [Slides]</a>  
          | <a class="post-link" href="https://youtu.be/8aWnM9p-UGM" target="_blank"><i class="fa-solid fa-video"></i> [Video]</a>  
        </span>
      </li>



      <li class="publist">
        <strong>Improving Fairness in Speaker Verification via Group-adapted Fusion Network</strong>
        <br>
        <span class="pubindent" ><strong style= "text-decoration: underline">Hua Shen*</strong>, Yuguang Yang*, Guoli Sun, Ryan Langman, Eunjung Han, Jasha Droppo, Andreas Stolcke</span>
        <br>
        <span class="pubindent"><a class="post-link" href="https://arxiv.org/pdf/2203.08788.pdf" target="_blank">ICASSP 2022</a>  
          | <a class="post-link" href="https://arxiv.org/abs/2202.11323" target="_blank"><i class='fas fa-atlas'></i> [Paper]</a>
          | <a class="post-link" href="https://github.com/huashen218/Voxceleb-Fairness" target="_blank"><i class="fa-brands fa-github"></i> [Github]</a>
          | <a class="post-link" href="/assets/files/submission-ICASSP22-poster.pdf" target="_blank"><i class="fa-solid fa-globe"></i> [Poster]</a>
          | <a class="post-link" href="/assets/files/submission-ICASSP22-presentation.pdf" target="_blank"><i class="fa-solid fa-video"></i> [Slides]</a>  
          | <a class="post-link" href="https://youtu.be/4QoHmQpG4Bc"><i class="fa-solid fa-video"></i> [Video]</a>  
        </span>
        <span class="pubindent text-primary" style="color:#D84C19; font-weight:bold"><i class="fa-solid fa-briefcase"></i>  Amazon AI Applied Scientist Intern</span>

      </li>


      <li class="publist">
        <strong>Explaining the Road Not Taken</strong>
        <br>
        <span class="pubindent" ><strong style= "text-decoration: underline">Hua Shen</strong>, Ting-Hao (Kenneth) Huang</span>
        <br>
        <span class="pubindent"><a class="post-link" href="https://human-centered-exnlp.github.io/" target="_blank">CHI 2021 HCXAI Workshop</a>  
          | <a class="post-link" href="https://arxiv.org/abs/2103.14973" target="_blank"><i class='fas fa-atlas'></i> [Paper]</a>
          | <a class="post-link" href="https://github.com/human-centered-exnlp/human-centered-exnlp.github.io" target="_blank"><i class="fa-brands fa-github"></i> [Github]</a>
          | <a class="post-link" href="https://human-centered-exnlp.github.io/" target="_blank"><i class="fa-solid fa-globe"></i> [Website]</a>
          | <a class="post-link" href="/assets/files/HCXAI21-presentation.pdf" target="_blank"><i class="fa-solid fa-video"></i> [Slides]</a> 
        </span>
        <span class="pubindent text-primary" style="color:#D84C19; font-weight:bold"><i class="fa-solid fa-star"></i> 200+ XAI Papers Survey</span>
      </li>

      <li class="publist">
        <strong>How Useful Are the Machine-Generated Interpretations to General Users? A Human Evaluation on Guessing the Incorrectly Predicted Labels</strong>
        <br>
        <span class="pubindent" ><strong style= "text-decoration: underline">Hua Shen</strong>, Ting-Hao (Kenneth) Huang</span>
        <br>
        <span class="pubindent"><a class="post-link" href="https://human-centered-exnlp.github.io/" target="_blank">AAAI HCOMP 2020</a>  
          | <a class="post-link" href="https://arxiv.org/abs/2008.11721" target="_blank"><i class='fas fa-atlas'></i> [Paper]</a>
          | <a class="post-link" href="https://github.com/huashen218/GuessWrongLabel"" target="_blank"><i class="fa-brands fa-github"></i> [Github]</a>
          | <a class="post-link" href="https://youtu.be/DlpQBTmQlcM" target="_blank"><i class="fa-solid fa-video"></i> [Video]</a> 
          | <a class="post-link" href="/assets/files/HCOMP20-presentation.pdf" target="_blank"><i class="fa-solid fa-video"></i> [Slides]</a> 
          | <a class="post-link" href="https://www.psu.edu/news/research/story/users-dont-understand-computer-explanations-image-labeling-errors/" target="_blank"><i class="fa-solid fa-globe"></i> [PennState NEWS]</a>
        </span>
      </li>

      <li class="publist">
        <span><strong>How to Teach Programming in the AI Era? Using LLMs as a Teachable Agent for Debugging</strong></span>
        <br>
        <span class="pubindent" >Qianou Christina Ma, <strong style= "text-decoration: underline">Hua Shen</strong>, Kenneth Koedinger, Tongshuang Wu</span>
        <br>
        <span class="pubindent"><a class="post-link" href="https://arxiv.org/pdf/2310.05292.pdf" target="_blank">AIED 2024</a>  | 
        <a class="post-link" href="https://arxiv.org/pdf/2310.05292.pdf" target="_blank">
          <i class='fas fa-atlas'></i> [Paper]</a>
        <span class="pubindent text-primary" style="color:#D84C19; font-weight:bold"><i class="fa-solid fa-trophy"></i> Best Paper</span>
        <span class="pubindent text-primary" style="color:#D84C19; font-weight:bold"><i class="fa-solid fa-trophy"></i> Best Interactive Event</span>
        </span>
      </li>


      <li class="publist">
        <strong>ScatterShot: Interactive In-context Example Curation for Text Transformation</strong>
        <br>
        <span class="pubindent" >Tongshuang Wu, <strong style= "text-decoration: underline">Hua Shen</strong>, Daniel S Weld, Jeffrey Heer, Marco Tulio Ribeiro</span>
        <br>
        <span class="pubindent"><a class="post-link" href="https://arxiv.org/pdf/2305.09770" target="_blank">IUI 2023</a>  
          | <a class="post-link" href="https://arxiv.org/abs/2302.07346" target="_blank"><i class='fas fa-atlas'></i> [Paper]</a>
          | <a class="post-link" href="https://github.com/tongshuangwu/scattershot" target="_blank"><i class="fa-brands fa-github"></i> [Github]</a>
          | <a class="post-link" href="/assets/files/IUI_scattershot.pdf" target="_blank"><i class="fa-solid fa-video"></i> [Slides]</a>  
        </span>
        <span class="pubindent text-primary" style="color:#D84C19; font-weight:bold"><i class="fa-solid fa-trophy"></i>  Best Paper Honorable Mention</span>
      </li>


      <li class="publist">
        <span><strong>Epistemic Alignment: A Mediating Framework for User-LLM Knowledge Delivery</strong></span>
        <br>
        <span class="pubindent" >Nicholas Clark, <strong style= "text-decoration: underline">Hua Shen</strong>,  Bill Howe, Tanu Mitra </span>
        <br>
        <span class="pubindent"><a class="post-link" href="/assets/files/2025_COLM.pdf" target="_blank">COLM 2025</a>  | 
        <a class="post-link" href="/assets/files/2025_COLM.pdf" target="_blank">
          <i class='fas fa-atlas'></i> [Paper]</a>
        </span>
      </li>


      <li class="publist">
        <span><strong>What Should We Engineer in Prompts? Training Humans in Requirement-Driven LLM Use</strong></span>
        <br>
        <span class="pubindent" >Qianou Ma, Weirui Peng, Chenyang Yang, <strong style= "text-decoration: underline">Hua Shen</strong>, Kenneth Koedinger, Tongshuang Wu</span>
        <br>
        <span class="pubindent"><a class="post-link" href="https://arxiv.org/pdf/2409.08775" target="_blank">TOCHI 2025</a>  |  
        <a class="post-link" href="https://arxiv.org/pdf/2409.08775" target="_blank">
          <i class='fas fa-atlas'></i> [Paper]</a>
        </span>
      </li>


      <li class="publist">
        <strong>“Here the GPT made a choice, and every choice can be biased”: How Students Critically Engage with LLMs through an End-User Auditing Activity</strong>
        <br>
        <span class="pubindent" >Snehal Prabhudesai, Ananya Kasi, Anmol Mansingh, Anindya Das Antar, <strong style= "text-decoration: underline">Hua Shen</strong>, Nikola Banovic</span>
        <br>
        <span class="pubindent"><a class="post-link" href="https://dl.acm.org/doi/pdf/10.1145/3706598.3713714" target="_blank">CHI 2025</a>  | 
        <a class="post-link" href="https://dl.acm.org/doi/pdf/10.1145/3706598.3713714" target="_blank">
          <i class='fas fa-atlas'></i> [Paper]</a>
        </span>
      </li>

      <li class="publist">
        <span><strong>NoMatterXAI: Generating "No Matter What" Alterfactual Examples for Explaining Black-Box Text Classification Models</strong></span>
        <br>
        <span class="pubindent" >Tuc Nguyen, James Michels, <strong style= "text-decoration: underline">Hua Shen</strong>, Thai Le</span>
        <br>
        <span class="pubindent"><a class="post-link" href="https://arxiv.org/pdf/2408.10528" target="_blank">AAAI 2025</a>  | 
        <a class="post-link" href="https://arxiv.org/pdf/2408.10528" target="_blank">
          <i class='fas fa-atlas'></i> [Paper]</a>
        </span>
      </li>


      <li class="publist">
        <span><strong>A Design Space for Intelligent and Interactive Writing Assistants</strong></span>
        <br>
        <span class="pubindent" >Mina Lee, Katy Llonka Gero, John Joon Young Chung, Simon Buckingham Shum, Vipul Raheja, <strong style= "text-decoration: underline">Hua Shen</strong>, Subhashini Venugopalan, Thiemo Wambsganss, David Zhou, (+27 authors) </span>
        <br>
        <span class="pubindent"><a class="post-link" href="https://arxiv.org/abs/2403.14117" target="_blank">CHI 2024</a>  | 
        <a class="post-link" href="https://arxiv.org/abs/2403.14117" target="_blank">
          <i class='fas fa-atlas'></i> [Paper]</a>  |
          <a class="post-link" href="https://writing-assistant.github.io/" target="_blank"><i class="fa-solid fa-globe"></i> [Website]</a>  |
          <a class="post-link" href="https://github.com/writing-assistant/writing-assistant.github.io" target="_blank"><i class="fa-brands fa-github"></i> [Github]</a>
        </span>
      </li>

      <li class="publist">
        <span><strong>SpeechPrompt: Prompting Speech Language Models for Speech Processing Tasks</strong></span>
        <br>
        <span class="pubindent" >Kai-Wei Chang, Haibin Wu, Yu-Kai Wang, Yuan-Kuei Wu, <strong style= "text-decoration: underline">Hua Shen</strong>, Wei-Cheng Tseng, Iu-thing Kang, Shang-Wen Li, Hung-yi Lee</span>
        <br>
        <span class="pubindent"><a class="post-link" href="https://ieeexplore.ieee.org/document/10620644" target="_blank">TASLP 2024</a>  | 
        <a class="post-link" href="https://ieeexplore.ieee.org/document/10620644" target="_blank">
          <i class='fas fa-atlas'></i> [Paper]</a>   
          | <a class="post-link" href="https://ga642381.github.io/SpeechPrompt/" target="_blank"><i class="fa-solid fa-globe"></i> [Website]</a>
          | <a class="post-link" href="https://github.com/ga642381/SpeechPrompt" target="_blank"><i class="fa-brands fa-github"></i> [Github]</a>
        </span>
      </li>




      <li class="publist">
        <span><strong>Gentopia.AI<img src="../assets/images/gentopia-logo.png" style="width:20px;height:20px;">: A Collaborative Platform for Tool-Augmented LLMs</strong></span>
        <br>
        <span class="pubindent" >Binfeng Xu, Xukun Liu, <strong style= "text-decoration: underline">Hua Shen</strong>, Zeyu Han, Yuhan Li, Murong Yue, Zhiyuan Peng, Yuchen Liu, Ziyu Yao, Dongkuan Xu</span>
        <br>
        <span class="pubindent"><a class="post-link" href="https://arxiv.org/pdf/2308.04030.pdf" target="_blank">EMNLP 2023 Demo</a>  
          | <a class="post-link" href="https://arxiv.org/pdf/2308.04030.pdf" target="_blank"><i class='fas fa-atlas'></i> [Paper]</a>
          | <a class="post-link" href="https://github.com/Gentopia-AI" target="_blank"><i class="fa-brands fa-github"></i> [Github]</a>
          | <a class="post-link" href="https://gentopia-ai.github.io/Gentopia-AI-Homepage/" target="_blank"><i class="fa-solid fa-globe"></i> [Homepage]</a>
          | <a class="post-link" href="https://www.youtube.com/watch?v=7dZ3ZvsI7sw" target="_blank"><i class="fa-solid fa-video"></i> [Tutorials]</a>  
        </span>
      </li>


      

      <li class="publist">
        <strong>Too Slow to Be Useful? On Incorporating Humans in the Loop of Smart Speakers</strong>
        <br>
        <span class="pubindent" >Shih-Hong Huang, Chieh-Yang Huang, Yuxin Deng, <strong style= "text-decoration: underline">Hua Shen</strong>, Szu-Chi Kuan, Ting-Hao K. Huang</span>
        <br>
        <span class="pubindent"><a class="post-link" href="https://arxiv.org/pdf/2212.03969.pdf" target="_blank">AAAI HCOMP 2022 Demo</a>  
          | <a class="post-link" href="https://arxiv.org/pdf/2212.03969.pdf" target="_blank"><i class='fas fa-atlas'></i> [Paper]</a>
        </span>
      </li>

      <li class="publist">
        <strong>Are Learners Satisfied with Their MOOC Experiences? Assessing and Improving Online Learners' Interactions.</strong>
        <br>
        <span class="pubindent" >Jiaqi Wang, <strong style= "text-decoration: underline">Hua Shen</strong>, Chacha Chen, Frank E. Ritter.</span>
        <br>
        <span class="pubindent"><a class="post-link" href="https://dl.acm.org/doi/fullHtml/10.1145/3429360.3468223#:~:text=Built%20on%20the%20survey%20results,they%20perhaps%20can%20be%20improved." target="_blank">Asian CHI Symposium 2021</a>  
          | <a class="post-link" href="https://dl.acm.org/doi/fullHtml/10.1145/3429360.3468223#:~:text=Built%20on%20the%20survey%20results,they%20perhaps%20can%20be%20improved." target="_blank"><i class='fas fa-atlas'></i> [Paper]</a>
      </li>

      
      <li class="publist">
        <strong>Interpretable Deep Learning under Fire</strong>
        <br>
        <span class="pubindent">Xinyang Zhang, Ningfei Wang, <strong style= "text-decoration: underline">Hua Shen</strong>, Shouling Ji, Xiapu Luo, Ting Wang</span>  
        <br>
        <span class="pubindent"><a class="post-link" href="https://arxiv.org/abs/1812.00891" target="_blank">USENIX 2020</a>  
          | <a class="post-link" href="https://arxiv.org/abs/1812.00891" target="_blank"><i class='fas fa-atlas'></i> [Paper]</a>
        </span>
      </li>


      <li class="publist">
        <strong>A Tale of Evil Twins: Adversarial Inputs versus Poisoned Models</strong>
        <br>
        <span class="pubindent">Ren Pang, <strong style= "text-decoration: underline">Hua Shen</strong>, Xinyang Zhang, Shouling Ji, Yevgeniy Vorobeychik, Xiapu Luo, Ting Wang</span>  
        <br>
        <span class="pubindent"><a class="post-link" href="https://arxiv.org/abs/1911.01559" target="_blank">CCS 2020</a>  
          | <a class="post-link" href="https://arxiv.org/abs/1911.01559" target="_blank"><i class='fas fa-atlas'></i> [Paper]</a>
        </span>
      </li>


      <li class="publist">
        <strong>A Quantitative Analysis Decision System Based on Deep Learning Integrated Algorithm and NSGA-II for FX Portfolio Prediction</strong>
        <br>
        <span class="pubindent"><strong style= "text-decoration: underline">Hua Shen</strong>, Xun Liang</span>  
        <br>
        <span class="pubindent"><a class="post-link" href="http://ieaaie2018.encs.concordia.ca/" target="_blank">IEA/AIE 2018</a>  
          | <a class="post-link" href="https://link.springer.com/chapter/10.1007/978-3-319-92058-0_55" target="_blank"><i class='fas fa-atlas'></i> [Paper]</a>
        </span>
      </li>



      <li class="publist">
        <strong>A Time Series Forecasting Model Based on Deep Learning Integrated Algorithm with Stacked Autoencoders and SVR for FX Prediction</strong>
        <br>
        <span class="pubindent"><strong style= "text-decoration: underline">Hua Shen</strong>, Xun Liang</span>  
        <br>
        <span class="pubindent"><a class="post-link" href="https://link.springer.com/book/10.1007/978-3-319-44781-0" target="_blank">ICANN 2016</a>  
          | <a class="post-link" href="/assets/files/Hua-Shen-Publication-ICANN-2016.pdf" target="_blank"><i class='fas fa-atlas'></i> [Paper]</a>
        </span>
      </li>

      <li class="publist">
        <strong>Emergency Decision Support Architectures for Bus Hijacking Based on Massive Image Anomaly Detection in Social Networks</strong>
        <br>
        <span class="pubindent"><strong style= "text-decoration: underline">Hua Shen</strong>, Xun Liang, Mingming Wang</span>  
        <br>
        <span class="pubindent"><a class="post-link" href="https://www.ieeesmc.org/publications/enewsletter/2015-ieee-international-conference-on-systems-man-and-cybernetics-2/" target="_blank">IEEE SMC 2015</a>  
          | <a class="post-link" href="/assets/files/Hua-Shen-Publication-IEEESMC-2015.pdf" target="_blank"><i class='fas fa-atlas'></i> [Paper]</a>
        </span>
      </li>

    </ol>
    </span>


    <div class="section-title"> <span>Book</span></div>
    <span>

      <li class="publist">
        <strong>Social Commerce Theory and Practice</strong>
        <br>
        <span class="pubindent">Xun Liang, Xiaoping Yang, <strong style= "text-decoration: underline">Hua Shen</strong></span>
        <br>
        <span class="pubindent"><a class="post-link" href="https://baike.baidu.com/item/%E7%A4%BE%E4%BC%9A%E5%8C%96%E5%95%86%E5%8A%A1%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E8%B7%B5/17543568?fr=aladdin" target="_blank">Tsinghua University Press, 2014, ISBN No.9787302381129</a>  
          | <a class="post-link" href="https://baike.baidu.com/item/%E7%A4%BE%E4%BC%9A%E5%8C%96%E5%95%86%E5%8A%A1%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E8%B7%B5/17543568?fr=aladdin" target="_blank"><i class='fas fa-atlas'></i> [Link]</a>
        </span>

      </li>

    </span>


    <div class="section-title"> <span>National Patents</span></div>

    <span>
      <li class="publist">
        <strong>A kind of completely new accident towards microblogging finds method</strong>
        <br>
        <span class="pubindent">Xun Liang, <strong style= "text-decoration: underline">Hua Shen</strong>, Run Cao</span>
        <br>
        <span class="pubindent"><a class="post-link" href="https://patents.google.com/patent/CN103577404B/en?oq=103577404" target="_blank">National Intellectual Property Administration, 2012, PRC (CNIPA). Patent No.CN103577404A.</a>  
          | <a class="post-link" href="https://patents.google.com/patent/CN103577404B/en?oq=103577404" target="_blank"><i class='fas fa-atlas'></i> [Link]</a>
        </span>
      </li>

      <li class="publist">
        <strong>A kind of cross-platform microblogging community account matching process</strong>
        <br>
        <span class="pubindent">Xiaofei Li, Xun Liang, Xiaoping Zhou, Xiaojing Shi, <strong style= "text-decoration: underline">Hua Shen</strong>, Haiyan Zhang</span>
        <br>
        <span class="pubindent"><a class="post-link" href="https://patents.google.com/patent/CN104765729B/en?oq=104765729" target="_blank">National Intellectual Property Administration, 2012, PRC (CNIPA). Patent No.CN104765729A.</a>  
          | <a class="post-link" href="https://patents.google.com/patent/CN104765729B/en?oq=104765729" target="_blank"><i class='fas fa-atlas'></i> [Link]</a>
        </span>
      </li>

    </span>

  </div>

</div>



    </main>

    <!-- ALL ICONS LINK HERE: https://github.com/goodinc/ctzn-ui/tree/gh-pages/assets/images/icons -->

<footer class="site-footer">

    <div class="wrapper">
        <ul class="footer-col footer-col-1">
            <span class="legal"><a class="" href="/">Stay Hungry, Stay Foolish</a></span>
            | 
            <span class="legal"> © <a class="" href="/">Hua Shen</a> (Last Updated: 2025-08)</span>
    </div>
    
</footer>

  </body>

</html>